{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "training_data = pd.read_excel(\"NPD_Data.xlsx\", header=0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Divides mapped from unmapped\n",
    "# testing_data = amazon[amazon[:,3] != \"Unmapped\"]\n",
    "# amazon_unmapped = amazon[amazon[:,3] == \"Unmapped\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divides description of each product into individual words\n",
    "def splitter(df):\n",
    "    split = [0]*df.shape[0]\n",
    "    # Useless strings to be removed\n",
    "    purge_list = [\"\",\"a\",\"and\",\"with\",\"for\",\"in\",\"the\",\"of\",\"to\",\"x\",\"disney\",\"-\",\"&\"]\n",
    "    \n",
    "    # Divides description into individual strings\n",
    "    for i in range(0,df.shape[0]):\n",
    "        split[i] = [x.lower() for x in (re.split('[ _,+\\'/#?:;()|]',str(df[i][0])))]\n",
    "        \n",
    "        for j in purge_list:\n",
    "            while(j in split[i]): \n",
    "                split[i].remove(j)\n",
    "    return split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_corpus = splitter(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not super useful, just counts occurences of each term in the entire sheet\n",
    "def count_occurrences(df):\n",
    "    dict = {}\n",
    "    for i in range(0,len(df)):\n",
    "        for j in range(0,len(df[i])):\n",
    "            if df[i][j] not in dict:\n",
    "                dict[df[i][j]] = {}\n",
    "            if i not in dict[df[i][j]]:\n",
    "                dict[df[i][j]][i] = 0\n",
    "            dict[df[i][j]][i] += 1\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_count = count_occurrences(training_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finds occurences of each property, e.g. \"Frozen\": 2000\n",
    "def count_properties(dic):\n",
    "    count = {}\n",
    "    for i in dic:\n",
    "        count[i] = 0\n",
    "        for j in dic[i]:\n",
    "            count[i] += dic[i][j]\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "CP = count_properties(training_count)\n",
    "# Sorts dictionary of properties into order of occurrence\n",
    "CP = {k: v for k, v in sorted(CP.items(), key=lambda item: item[1], reverse=True)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lists to be used for training\n",
    "X = training_data[:,1]\n",
    "y = training_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 % complete...\n",
      "Elapsed time: 3.6166666666666667 minutes\n",
      "\n",
      "20 % complete...\n",
      "Elapsed time: 10.8 minutes\n",
      "\n",
      "30 % complete...\n",
      "Elapsed time: 18.183333333333334 minutes\n",
      "\n",
      "40 % complete...\n",
      "Elapsed time: 25.816666666666666 minutes\n",
      "\n",
      "50 % complete...\n",
      "Elapsed time: 35.28333333333333 minutes\n",
      "\n",
      "60 % complete...\n",
      "Elapsed time: 47.0 minutes\n",
      "\n",
      "70 % complete...\n",
      "Elapsed time: 56.36666666666667 minutes\n",
      "\n",
      "80 % complete...\n",
      "Elapsed time: 66.11666666666666 minutes\n",
      "\n",
      "90 % complete...\n",
      "Elapsed time: 74.48333333333333 minutes\n",
      "\n",
      "100 % complete...\n",
      "Elapsed time: 82.81666666666666 minutes\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This will take FOREVER, so just let it sit and run for a good 1h 20mins\n",
    "count = 0\n",
    "trainingDict = {}\n",
    "# Go through all the properties and the list of products and add each indivdual word of item description to the property it associates with and tally the occurences of this word\n",
    "# Word will then build an \"identity of words that are commonly used with it.\n",
    "load = len(CP)\n",
    "prev = 0\n",
    "start_time = time.time()\n",
    "for listKeyword in CP:\n",
    "    if round((count/load)*10) != prev:\n",
    "            print(round((count/load)*10)*10, \"% complete...\")\n",
    "            t = time.time() - start_time\n",
    "            print(\"Elapsed time:\", round((t)-(t%1))/60, \"minutes\\n\")\n",
    "            prev = round((count/load)*10)\n",
    "    for j in range(len(y)):\n",
    "        for keyword in y[j]:\n",
    "            if listKeyword == keyword:\n",
    "                if X[j] not in trainingDict:\n",
    "                    trainingDict[X[j]] = {}\n",
    "                if listKeyword not in trainingDict[X[j]]:\n",
    "                    trainingDict[X[j]][listKeyword] = 1\n",
    "                else:\n",
    "                    trainingDict[X[j]][listKeyword] += 1\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2704\n"
     ]
    }
   ],
   "source": [
    "for i in list(trainingDict):\n",
    "    for j in list(trainingDict[i]):\n",
    "        if trainingDict[i][j] == 1:\n",
    "            del trainingDict[i][j]\n",
    "\n",
    "del trainingDict[\"All Other\"]\n",
    "del trainingDict[\"Other License\"]\n",
    "# Number of unique properties used in training set\n",
    "print(len(trainingDict))\n",
    "pickle.dump(trainingDict, open(\"TrainingData.p\",\"wb\"))\n",
    "\n",
    "# Will print FAT list of properties and list of words used with it. Just scroll past it.\n",
    "# for i in trainingDict:\n",
    "#     print(i)\n",
    "#     print(trainingDict[i])\n",
    "#     print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
